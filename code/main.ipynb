{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import trange\n",
    "import os, sys, zipfile\n",
    "import shutil\n",
    "import urllib.request\n",
    "import requests\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageFile\n",
    "from pycocotools.coco import COCO\n",
    "%matplotlib inline\n",
    "base_size = 513\n",
    "crop_size = 513\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record package versions for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"os: {}\".format(os.name))\n",
    "print(\"sys: {}\".format(sys.version))\n",
    "print(\"numpy: {}, {}\".format(np.__version__, np.__file__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = 'dataloaders/datasets/coco_dataset'\n",
    "dataType = 'val2017'\n",
    "annDir = '{}/annotations'.format(dataDir)\n",
    "annZipFile = '{}/annotations_train{}.zip'.format(dataDir, dataType)\n",
    "annFile = '{}/instances_{}.json'.format(annDir, dataType)\n",
    "annURL = 'http://images.cocodataset.org/annotations/annotations_train{}.zip'.format(dataType)\n",
    "print(f'annDir: {annDir}')\n",
    "print(f'annFile: {annFile}')\n",
    "print(f'annZipFile: {annZipFile}')\n",
    "print(f'annURL: {annURL}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data if not available locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(annDir):\n",
    "    os.makedirs(annDir)\n",
    "if not os.path.exists(annFile):\n",
    "    if not os.path.exists(annZipFile):\n",
    "        print(\"Downloading zipped annotations to \" + annZipFile + \" ...\")\n",
    "        with urllib.request.urlopen(annURL) as resp, open(annZipFile, 'wb') as out:\n",
    "            shutil.copyfileobj(resp, out)\n",
    "        print(\"... done downloading\")\n",
    "    print(\"Unzipping \" + annZipFile)\n",
    "    with zipfile.ZipFile(annZipFile, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(dataDir)\n",
    "    print(\"... done unzipping\")\n",
    "print(\"will use annotations in \" + annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize COCO API for instance annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO(annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display COCO categories and supercategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = coco.loadCats(coco.getCatIds())\n",
    "nms = [cat['name'] for cat in cats]\n",
    "print('COCO categories: \\n{}\\n'.format(' '.join(nms)))\n",
    "nms = set([cat['supercategory'] for cat in cats])\n",
    "print('COCO supercategories: \\n{}'.format(' '.join(nms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coco.cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get all images containing given categories, for an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catIds = coco.getCatIds(catNms=['person', 'dog', 'skateboard'])\n",
    "imgIds = coco.getImgIds(catIds=catIds)\n",
    "imgs = coco.loadImgs(imgIds[1])\n",
    "annIds = coco.getAnnIds(imgIds=imgIds[1])\n",
    "anns = coco.loadAnns(annIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in imgs:\n",
    "    I = io.imread(img['coco_url'])\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(15, 15))\n",
    "    ax1.axis('off')\n",
    "    ax1.imshow(I) \n",
    "    ax2.axis('off')\n",
    "    ax2.imshow(I)    \n",
    "    annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    coco.showAnns(anns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download 2017 validation images for simplicity\n",
    "A size of training images is too large for data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catIds = coco.getCatIds()\n",
    "imgIds = coco.getImgIds()\n",
    "imgs = coco.loadImgs(imgIds)\n",
    "imgType = 'val2017'\n",
    "imgDir = 'dataloaders/datasets/coco_dataset/{}/'.format(imgType)\n",
    "if not os.path.exists(imgDir):\n",
    "    os.makedirs(imgDir)\n",
    "    for im in imgs:\n",
    "        img_data = requests.get(im['coco_url']).content\n",
    "        with open(imgDir + im['file_name'], 'wb') as handler:\n",
    "            handler.write(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download 2017 training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = 'dataloaders/datasets/coco_dataset'\n",
    "dataType = 'train2017'\n",
    "annDir = '{}/annotations'.format(dataDir)\n",
    "annFile = '{}/instances_{}.json'.format(annDir, dataType)\n",
    "print(f'annDir: {annDir}')\n",
    "print(f'annFile: {annFile}')\n",
    "coco = COCO(annFile)\n",
    "imgIds = coco.getImgIds()\n",
    "imgs = coco.loadImgs(imgIds)\n",
    "imgType = 'train2017'\n",
    "imgDir = 'dataloaders/datasets/coco_dataset/{}/'.format(imgType)\n",
    "# if not os.path.exists(imgDir):\n",
    "#   os.makedirs(imgDir)\n",
    "for im in imgs:\n",
    "    img_path = imgDir + im['file_name']\n",
    "    if os.path.exists(img_path):\n",
    "      continue\n",
    "    img_data = requests.get(im['coco_url']).content\n",
    "    with open(imgDir + im['file_name'], 'wb') as handler:\n",
    "        handler.write(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.datasets import coco\n",
    "from modeling.deeplab import *\n",
    "from modeling.unet import *\n",
    "from utils.loss import SegmentationLosses\n",
    "from utils.lr_scheduler import LR_Scheduler\n",
    "from modeling.sync_batchnorm.replicate import patch_replication_callback\n",
    "from dataloaders import make_data_loader\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import config as args\n",
    "from utils.saver import Saver\n",
    "from utils.summaries import TensorboardSummary\n",
    "from utils.metrics import Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        # Define Saver\n",
    "        self.saver = Saver(args)\n",
    "        self.saver.save_experiment_config()\n",
    "        # Define Tensorboard Summary\n",
    "        self.summary = TensorboardSummary(self.saver.experiment_dir)\n",
    "        self.writer = self.summary.create_summary()\n",
    "\n",
    "        kwargs = {'num_workers': args.workers, 'pin_memory': True}\n",
    "        self.train_loader, self.val_loader, self.test_loader, self.nclass = make_data_loader(args, **kwargs)\n",
    "        \n",
    "        self.cuda = args.useCUDA and torch.cuda.is_available()\n",
    "        if self.cuda:\n",
    "            gpu_ids = [int(s) for s in args.gpu_ids.split(',')]\n",
    "        if self.cuda and len(args.gpu_ids) > 1:\n",
    "            args.sync_bn = True\n",
    "        else:\n",
    "            args.sync_bn = False\n",
    "        # Define network\n",
    "        # DeepLab version\n",
    "        model = DeepLab(backbone=args.backbone, output_stride=args.out_stride, num_classes=self.nclass, sync_bn=args.sync_bn, \n",
    "                        freeze_bn=args.freeze_bn)\n",
    "      # set different learning rate for backbone(ResNet101), Atrous Spatial Pyramid Pooling and decoder part\n",
    "        train_params = [{'params': model.get_1x_lr_params(), 'lr': args.lr}, \n",
    "                        {'params': model.get_10x_lr_params(), 'lr': args.lr * 10}]\n",
    "        # Define Optimizer\n",
    "        optimizer = torch.optim.SGD(train_params, momentum=args.momentum,\n",
    "                                    weight_decay=args.weight_decay, nesterov=args.nesterov)\n",
    "        # UNet version\n",
    "#         model = UNet(num_classes=self.nclass, sync_bn=args.sync_bn, freeze_bn=args.freeze_bn)\n",
    "#         optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay, nesterov=args.nesterov)\n",
    "        \n",
    "        weight = None\n",
    " \n",
    "        \n",
    "        self.criterion = SegmentationLosses(weight=weight, cuda=self.cuda).build_loss(mode=args.loss_type) #pytorch cross-entropy loss\n",
    "        self.model, self.optimizer = model, optimizer\n",
    "        self.evaluator = Evaluator(self.nclass)\n",
    "        self.scheduler = LR_Scheduler(args.lr_scheduler, args.lr, args.epochs, len(self.train_loader))\n",
    "        \n",
    "            # Using cuda\n",
    "        if self.cuda:\n",
    "            self.model = torch.nn.DataParallel(self.model, device_ids=gpu_ids) # only use single GPU in my local machine\n",
    "            patch_replication_callback(self.model) # replicate the model to each GPU\n",
    "            self.model = self.model.cuda()\n",
    "            \n",
    "        # Resuming checkpoint\n",
    "        self.best_pred = 0.0\n",
    "        if args.resume is not None:\n",
    "            if not os.path.isfile(args.resume):\n",
    "                raise RuntimeError(\"=> no checkpoint found at '{}'\" .format(args.resume))\n",
    "            checkpoint = torch.load(args.resume)\n",
    "#             args.start_epoch = checkpoint['epoch']\n",
    "            args.start_epoch = 0\n",
    "            if self.cuda:\n",
    "                self.model.module.load_state_dict(checkpoint['state_dict'])\n",
    "            else:\n",
    "                self.model.load_state_dict(checkpoint['state_dict'])\n",
    "#             if not args.ft:\n",
    "#                 self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            self.best_pred = checkpoint['best_pred']\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.resume, checkpoint['epoch']))\n",
    "        \n",
    "    def training(self, epoch):\n",
    "        train_loss = 0.0\n",
    "        self.model.train()\n",
    "        tbar = tqdm(self.train_loader)\n",
    "        num_img_tr = len(self.train_loader)\n",
    "        \n",
    "        for i, sample in enumerate(tbar):\n",
    "            image, target = sample['image'], sample['label']\n",
    "            if self.cuda:\n",
    "                image, target = image.cuda(), target.cuda() # send mini-batches to GPU\n",
    "            self.scheduler(self.optimizer, i, epoch, self.best_pred)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(image)\n",
    "            loss = self.criterion(output, target)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            tbar.set_description('Train loss: {0:.3f}'.format(train_loss / (i + 1))) # keep track of average train loss\n",
    "            self.writer.add_scalar('train/total_loss_iter', loss.item(), i + num_img_tr * epoch)\n",
    "            # Show 10 * 3 inference results each epoch\n",
    "            if i % (num_img_tr // 10) == 0:\n",
    "                global_step = i + num_img_tr * epoch\n",
    "                self.summary.visualize_image(self.writer, self.args.dataset, image, target, output, global_step)\n",
    "\n",
    "        self.writer.add_scalar('train/total_loss_epoch', train_loss, epoch)\n",
    "        print('[Epoch: {0:d}, numImages: {1:5d}]'.format(epoch+1, i * self.args.batch_size + image.data.shape[0]))\n",
    "        print('Loss: {0:.3f}'.format(train_loss))\n",
    "\n",
    "    def validation(self, epoch):\n",
    "        self.model.eval()\n",
    "        self.evaluator.reset()\n",
    "        tbar = tqdm(self.val_loader, desc='\\r')\n",
    "        num_img_vl = len(self.val_loader)\n",
    "        val_loss = 0.0\n",
    "\n",
    "        for i, sample in enumerate(tbar):\n",
    "            image, target = sample['image'], sample['label']\n",
    "            if self.cuda:\n",
    "                image, target = image.cuda(), target.cuda()\n",
    "            with torch.no_grad(): # no backpropagation for model evaludation\n",
    "                output = self.model(image)\n",
    "            loss = self.criterion(output, target)\n",
    "            val_loss += loss.item()\n",
    "            tbar.set_description('Validation loss: {0:.3f}'.format(val_loss / (i + 1)))\n",
    "            if i % (num_img_vl // 10) == 0:\n",
    "                global_step = i + num_img_vl * epoch\n",
    "                self.summary.visualize_image(self.writer, self.args.dataset, image, target, output, global_step)\n",
    "                \n",
    "            pred = output.data.cpu().numpy()\n",
    "            target = target.cpu().numpy()\n",
    "            pred = np.argmax(pred, axis=1)\n",
    "            # Add batch sample into evaluator\n",
    "            # this will generate confusion matrix row: ground_truth, col: predicted label\n",
    "            self.evaluator.add_batch(target, pred)\n",
    "           \n",
    "\n",
    "        # Fast evaludation during training\n",
    "        Acc = self.evaluator.Pixel_Accuracy()\n",
    "        Acc_class = self.evaluator.Pixel_Accuracy_Class()\n",
    "        mIoU = self.evaluator.Mean_Intersection_over_Union()\n",
    "        FWIoU = self.evaluator.Frequency_Weighted_Intersection_over_Union()\n",
    "\n",
    "        # Write current evaluation metrics to tensorboard\n",
    "        self.writer.add_scalar('val/total_loss_epoch', val_loss, epoch)\n",
    "        self.writer.add_scalar('val/mIoU', mIoU, epoch)\n",
    "        self.writer.add_scalar('val/Acc', Acc, epoch)\n",
    "        self.writer.add_scalar('val/Acc_class', Acc_class, epoch)\n",
    "        self.writer.add_scalar('val/fwIoU', FWIoU, epoch)\n",
    "        print('Validation:')\n",
    "        print('[Epoch: {0:d}, numImages: {1:5d}]'.format(epoch+1, i * self.args.batch_size + image.data.shape[0]))\n",
    "        print(\"Acc:{}, Acc_class:{}, mIoU:{}, fwIoU: {}\".format(Acc, Acc_class, mIoU, FWIoU))\n",
    "        print('Loss: {0:.3f}'.format(val_loss))\n",
    "\n",
    "        new_pred = mIoU\n",
    "        if new_pred > self.best_pred:\n",
    "            is_best = True\n",
    "            self.best_pred = new_pred\n",
    "            self.saver.save_checkpoint({'epoch': epoch + 1, 'state_dict': self.model.module.state_dict(), \n",
    "                                        'optimizer': self.optimizer.state_dict(), 'best_pred': self.best_pred}, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42) # set random seed for both CPU and GPU\n",
    "trainer = Trainer(args)\n",
    "print('Starting Epoch:', trainer.args.start_epoch)\n",
    "print('Total Epoches:', trainer.args.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0, trainer.args.epochs):\n",
    "    if trainer.args.do_train:\n",
    "        trainer.training(epoch)\n",
    "    if not trainer.args.no_val and epoch % args.eval_interval == (args.eval_interval - 1):\n",
    "        trainer.validation(epoch)\n",
    "trainer.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
