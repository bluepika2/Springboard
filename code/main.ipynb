{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import trange\n",
    "import os, sys, zipfile\n",
    "import shutil\n",
    "import urllib.request\n",
    "import requests\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageFile\n",
    "from pycocotools.coco import COCO\n",
    "%matplotlib inline\n",
    "base_size = 513\n",
    "crop_size = 513\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record package versions for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"os: {}\".format(os.name))\n",
    "print(\"sys: {}\".format(sys.version))\n",
    "print(\"numpy: {}, {}\".format(np.__version__, np.__file__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = 'dataloaders/datasets/coco_dataset'\n",
    "dataType = 'val2017'\n",
    "annDir = '{}/annotations'.format(dataDir)\n",
    "annZipFile = '{}/annotations_train{}.zip'.format(dataDir, dataType)\n",
    "annFile = '{}/instances_{}.json'.format(annDir, dataType)\n",
    "annURL = 'http://images.cocodataset.org/annotations/annotations_train{}.zip'.format(dataType)\n",
    "print(f'annDir: {annDir}')\n",
    "print(f'annFile: {annFile}')\n",
    "print(f'annZipFile: {annZipFile}')\n",
    "print(f'annURL: {annURL}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data if not available locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(annDir):\n",
    "    os.makedirs(annDir)\n",
    "if not os.path.exists(annFile):\n",
    "    if not os.path.exists(annZipFile):\n",
    "        print(\"Downloading zipped annotations to \" + annZipFile + \" ...\")\n",
    "        with urllib.request.urlopen(annURL) as resp, open(annZipFile, 'wb') as out:\n",
    "            shutil.copyfileobj(resp, out)\n",
    "        print(\"... done downloading\")\n",
    "    print(\"Unzipping \" + annZipFile)\n",
    "    with zipfile.ZipFile(annZipFile, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(dataDir)\n",
    "    print(\"... done unzipping\")\n",
    "print(\"will use annotations in \" + annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize COCO API for instance annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO(annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display COCO categories and supercategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = coco.loadCats(coco.getCatIds())\n",
    "nms = [cat['name'] for cat in cats]\n",
    "print('COCO categories: \\n{}\\n'.format(' '.join(nms)))\n",
    "nms = set([cat['supercategory'] for cat in cats])\n",
    "print('COCO supercategories: \\n{}'.format(' '.join(nms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coco.cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get all images containing given categories, for an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catIds = coco.getCatIds(catNms=['person', 'dog', 'skateboard'])\n",
    "imgIds = coco.getImgIds(catIds=catIds)\n",
    "imgs = coco.loadImgs(imgIds[1])\n",
    "annIds = coco.getAnnIds(imgIds=imgIds[1])\n",
    "anns = coco.loadAnns(annIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in imgs:\n",
    "    I = io.imread(img['coco_url'])\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(15, 15))\n",
    "    ax1.axis('off')\n",
    "    ax1.imshow(I) \n",
    "    ax2.axis('off')\n",
    "    ax2.imshow(I)    \n",
    "    annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    coco.showAnns(anns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download 2017 validation images for simplicity\n",
    "A size of training images is too large for data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catIds = coco.getCatIds()\n",
    "imgIds = coco.getImgIds()\n",
    "imgs = coco.loadImgs(imgIds)\n",
    "imgType = 'val2017'\n",
    "imgDir = 'dataloaders/datasets/coco_dataset/{}/'.format(imgType)\n",
    "if not os.path.exists(imgDir):\n",
    "    os.makedirs(imgDir)\n",
    "    for im in imgs:\n",
    "        img_data = requests.get(im['coco_url']).content\n",
    "        with open(imgDir + im['file_name'], 'wb') as handler:\n",
    "            handler.write(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.datasets import coco\n",
    "from modeling.deeplab import *\n",
    "from modeling.unet import *\n",
    "from utils.loss import SegmentationLosses\n",
    "from utils.lr_scheduler import LR_Scheduler\n",
    "from modeling.sync_batchnorm.replicate import patch_replication_callback\n",
    "from dataloaders import make_data_loader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import config as args\n",
    "from utils.saver import Saver\n",
    "from utils.summaries import TensorboardSummary\n",
    "from utils.metrics import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        # Define Saver\n",
    "        self.saver = Saver(args)\n",
    "        self.saver.save_experiment_config()\n",
    "        # Define Tensorboard Summary\n",
    "        self.summary = TensorboardSummary(self.saver.experiment_dir)\n",
    "        self.writer = self.summary.create_summary()\n",
    "\n",
    "        kwargs = {'num_workers': args.workers, 'pin_memory': True}\n",
    "        self.train_loader, self.val_loader, self.test_loader, self.nclass = make_data_loader(args, **kwargs)\n",
    "        \n",
    "        self.cuda = args.useCUDA and torch.cuda.is_available()\n",
    "        if self.cuda:\n",
    "            args.gpu_ids = [int(s) for s in args.gpu_ids.split(',')]\n",
    "        if self.cuda and len(args.gpu_ids) > 1:\n",
    "            args.sync_bn = True\n",
    "        else:\n",
    "            args.sync_bn = False\n",
    "        # Define network\n",
    "        # DeepLab version\n",
    "#         model = DeepLab(backbone=args.backbone, output_stride=args.out_stride, num_classes=self.nclass, sync_bn=args.sync_bn, \n",
    "#                         freeze_bn=args.freeze_bn)\n",
    "#       # set different learning rate for backbone(ResNet101), Atrous Spatial Pyramid Pooling and decoder part\n",
    "#         train_params = [{'params': model.get_1x_lr_params(), 'lr': args.lr}, \n",
    "#                         {'params': model.get_10x_lr_params(), 'lr': args.lr * 10}]\n",
    "#         # Define Optimizer\n",
    "#         optimizer = torch.optim.SGD(train_params, momentum=args.momentum,\n",
    "#                                     weight_decay=args.weight_decay, nesterov=args.nesterov)\n",
    "        # UNet version\n",
    "        model = UNet(num_classes=self.nclass, sync_bn=args.sync_bn, freeze_bn=args.freeze_bn)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay, nesterov=args.nesterov)\n",
    "        \n",
    "        weight = None\n",
    " \n",
    "        \n",
    "        self.criterion = SegmentationLosses(weight=weight, cuda=self.cuda).build_loss(mode=args.loss_type) #pytorch cross-entropy loss\n",
    "        self.model, self.optimizer = model, optimizer\n",
    "        self.evaluator = Evaluator(self.nclass)\n",
    "        self.scheduler = LR_Scheduler(args.lr_scheduler, args.lr, args.epochs, len(self.train_loader))\n",
    "        \n",
    "            # Using cuda\n",
    "        if self.cuda:\n",
    "            self.model = torch.nn.DataParallel(self.model, device_ids=args.gpu_ids) # only use single GPU in my local machine\n",
    "            patch_replication_callback(self.model) # replicate the model to each GPU\n",
    "            self.model = self.model.cuda()\n",
    "        self.best_pred = 0.0\n",
    "        \n",
    "    def training(self, epoch):\n",
    "        train_loss = 0.0\n",
    "        self.model.train()\n",
    "        tbar = tqdm(self.train_loader)\n",
    "        num_img_tr = len(self.train_loader)\n",
    "    \n",
    "        for i, sample in enumerate(tbar):\n",
    "#             import pdb; pdb.set_trace()\n",
    "            image, target = sample['image'], sample['label']\n",
    "            if self.cuda:\n",
    "                image, target = image.cuda(), target.cuda() # send mini-batches to GPU\n",
    "            self.scheduler(self.optimizer, i, epoch, self.best_pred)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(image)\n",
    "            loss = self.criterion(output, target)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            tbar.set_description('Train loss: {0:.3f}'.format(train_loss / (i + 1))) # keep track of average train loss\n",
    "            self.writer.add_scalar('train/total_loss_iter', loss.item(), i + num_img_tr * epoch)\n",
    "            # Show 10 * 3 inference results each epoch\n",
    "            if i % (num_img_tr // 10) == 0:\n",
    "                global_step = i + num_img_tr * epoch\n",
    "                self.summary.visualize_image(self.writer, self.args.dataset, image, target, output, global_step)\n",
    "\n",
    "        self.writer.add_scalar('train/total_loss_epoch', train_loss, epoch)\n",
    "        print('[Epoch: {0:d}, numImages: {1:5d}]'.format(epoch+1, i * self.args.batch_size + image.data.shape[0]))\n",
    "        print('Loss: {0:.3f}'.format(train_loss))\n",
    "\n",
    "    def validation(self, epoch):\n",
    "        self.model.eval()\n",
    "        self.evaluator.reset()\n",
    "        tbar = tqdm(self.val_loader, desc='\\r')\n",
    "        val_loss = 0.0\n",
    "\n",
    "        for i, sample in enumerate(tbar):\n",
    "            image, target = sample['image'], sample['label']\n",
    "            if self.cuda:\n",
    "                image, target = image.cuda(), target.cuda()\n",
    "                with torch.no_grad(): # no backpropagation for model evaludation\n",
    "                    output = self.model(image)\n",
    "                loss = self.criterion(output, target)\n",
    "                val_loss += loss.item()\n",
    "                tbar.set_description('Validation loss: {0:.3f}'.format(val_loss / (i + 1)))\n",
    "                pred = output.data.cpu().numpy()\n",
    "                target = target.cpu().numpy()\n",
    "                pred = np.argmax(pred, axis=1)\n",
    "                # Add batch sample into evaluator\n",
    "                # this will generate confusion matrix row: ground_truth, col: predicted label\n",
    "                self.evaluator.add_batch(target, pred)\n",
    "\n",
    "        # Fast evaludation during training\n",
    "        Acc = self.evaluator.Pixel_Accuracy()\n",
    "        Acc_class = self.evaluator.Pixel_Accuracy_Class()\n",
    "        mIoU = self.evaluator.Mean_Intersection_over_Union()\n",
    "        FWIoU = self.evaluator.Frequency_Weighted_Intersection_over_Union()\n",
    "\n",
    "        # Write current evaluation metrics to tensorboard\n",
    "        self.writer.add_scalar('val/total_loss_epoch', val_loss, epoch)\n",
    "        self.writer.add_scalar('val/mIoU', mIoU, epoch)\n",
    "        self.writer.add_scalar('val/Acc', Acc, epoch)\n",
    "        self.writer.add_scalar('val/Acc_class', Acc_class, epoch)\n",
    "        self.writer.add_scalar('val/fwIoU', FWIoU, epoch)\n",
    "        print('Validation:')\n",
    "        print('[Epoch: {0:d}, numImages: {1:5d}]'.format(epoch+1, i * self.args.batch_size + image.data.shape[0]))\n",
    "        print(\"Acc:{}, Acc_class:{}, mIoU:{}, fwIoU: {}\".format(Acc, Acc_class, mIoU, FWIoU))\n",
    "        print('Loss: {0:.3f}'.format(val_loss))\n",
    "\n",
    "        new_pred = mIoU\n",
    "        if new_pred > self.best_pred:\n",
    "            is_best = True\n",
    "            self.best_pred = new_pred\n",
    "            self.saver.save_checkpoint({'epoch': epoch + 1, 'state_dict': self.model.module.state_dict(), \n",
    "                                        'optimizer': self.optimizer.state_dict(), 'best_pred': self.best_pred}, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.57s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.72s)\n",
      "creating index...\n",
      "index created!\n",
      "Using poly LR Scheduler!\n",
      "Total Epoches: 3\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42) # set random seed for both CPU and GPU\n",
    "trainer = Trainer(args)\n",
    "print('Total Epoches:', trainer.args.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1950 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=>Epoches 0, learning rate = 0.1000,                 previous best = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bluep\\Anaconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\functional.py:2416: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "C:\\Users\\bluep\\Anaconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\functional.py:2503: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n",
      "C:\\Users\\bluep\\Anaconda3\\envs\\capstone\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Train loss: 0.577: 100%|██████████| 1950/1950 [27:56<00:00,  1.16it/s]\n",
      "  0%|          | 0/1950 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1, numImages:  3899]\n",
      "Loss: 1125.921\n",
      "\n",
      "=>Epoches 1, learning rate = 0.0694,                 previous best = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.555: 100%|██████████| 1950/1950 [27:52<00:00,  1.17it/s]\n",
      ":   0%|          | 0/1950 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 2, numImages:  3899]\n",
      "Loss: 1083.023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.543: 100%|██████████| 1950/1950 [13:32<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "[Epoch: 2, numImages:  3899]\n",
      "Acc:0.724710745393259, Acc_class:0.04800431726249123, mIoU:0.0349509779197328, fwIoU: 0.5261700152457511\n",
      "Loss: 1059.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1950 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=>Epoches 2, learning rate = 0.0372,                 previous best = 0.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.540: 100%|██████████| 1950/1950 [27:53<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 3, numImages:  3899]\n",
      "Loss: 1052.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, trainer.args.epochs):\n",
    "        trainer.training(epoch)\n",
    "        if not trainer.args.no_val and epoch % args.eval_interval == (args.eval_interval - 1):\n",
    "            trainer.validation(epoch)\n",
    "trainer.writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
