{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import trange\n",
    "import os, sys, zipfile\n",
    "import shutil\n",
    "import urllib.request\n",
    "import requests\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageFile\n",
    "from pycocotools.coco import COCO\n",
    "%matplotlib inline\n",
    "base_size = 513\n",
    "crop_size = 513\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record package versions for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"os: {}\".format(os.name))\n",
    "print(\"sys: {}\".format(sys.version))\n",
    "print(\"numpy: {}, {}\".format(np.__version__, np.__file__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = 'dataloaders/datasets/coco_dataset'\n",
    "dataType = 'val2017'\n",
    "annDir = '{}/annotations'.format(dataDir)\n",
    "annZipFile = '{}/annotations_train{}.zip'.format(dataDir, dataType)\n",
    "annFile = '{}/instances_{}.json'.format(annDir, dataType)\n",
    "annURL = 'http://images.cocodataset.org/annotations/annotations_train{}.zip'.format(dataType)\n",
    "print(f'annDir: {annDir}')\n",
    "print(f'annFile: {annFile}')\n",
    "print(f'annZipFile: {annZipFile}')\n",
    "print(f'annURL: {annURL}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data if not available locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(annDir):\n",
    "    os.makedirs(annDir)\n",
    "if not os.path.exists(annFile):\n",
    "    if not os.path.exists(annZipFile):\n",
    "        print(\"Downloading zipped annotations to \" + annZipFile + \" ...\")\n",
    "        with urllib.request.urlopen(annURL) as resp, open(annZipFile, 'wb') as out:\n",
    "            shutil.copyfileobj(resp, out)\n",
    "        print(\"... done downloading\")\n",
    "    print(\"Unzipping \" + annZipFile)\n",
    "    with zipfile.ZipFile(annZipFile, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(dataDir)\n",
    "    print(\"... done unzipping\")\n",
    "print(\"will use annotations in \" + annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize COCO API for instance annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO(annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display COCO categories and supercategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = coco.loadCats(coco.getCatIds())\n",
    "nms = [cat['name'] for cat in cats]\n",
    "print('COCO categories: \\n{}\\n'.format(' '.join(nms)))\n",
    "nms = set([cat['supercategory'] for cat in cats])\n",
    "print('COCO supercategories: \\n{}'.format(' '.join(nms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coco.cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get all images containing given categories, for an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catIds = coco.getCatIds(catNms=['person', 'dog', 'skateboard'])\n",
    "imgIds = coco.getImgIds(catIds=catIds)\n",
    "imgs = coco.loadImgs(imgIds[1])\n",
    "annIds = coco.getAnnIds(imgIds=imgIds[1])\n",
    "anns = coco.loadAnns(annIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in imgs:\n",
    "    I = io.imread(img['coco_url'])\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(15, 15))\n",
    "    ax1.axis('off')\n",
    "    ax1.imshow(I) \n",
    "    ax2.axis('off')\n",
    "    ax2.imshow(I)    \n",
    "    annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    coco.showAnns(anns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download 2017 validation images for simplicity\n",
    "A size of training images is too large for data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catIds = coco.getCatIds()\n",
    "imgIds = coco.getImgIds()\n",
    "imgs = coco.loadImgs(imgIds)\n",
    "imgType = 'val2017'\n",
    "imgDir = 'dataloaders/datasets/coco_dataset/{}/'.format(imgType)\n",
    "if not os.path.exists(imgDir):\n",
    "    os.makedirs(imgDir)\n",
    "    for im in imgs:\n",
    "        img_data = requests.get(im['coco_url']).content\n",
    "        with open(imgDir + im['file_name'], 'wb') as handler:\n",
    "            handler.write(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.datasets import coco\n",
    "from modeling.deeplab import *\n",
    "from modeling.unet import *\n",
    "from utils.loss import SegmentationLosses\n",
    "from utils.lr_scheduler import LR_Scheduler\n",
    "from modeling.sync_batchnorm.replicate import patch_replication_callback\n",
    "from dataloaders import make_data_loader\n",
    "from tqdm import tqdm\n",
    "import config as args\n",
    "from utils.saver import Saver\n",
    "from utils.summaries import TensorboardSummary\n",
    "from utils.metrics import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        # Define Saver\n",
    "        self.saver = Saver(args)\n",
    "        self.saver.save_experiment_config()\n",
    "        # Define Tensorboard Summary\n",
    "        self.summary = TensorboardSummary(self.saver.experiment_dir)\n",
    "        self.writer = self.summary.create_summary()\n",
    "\n",
    "        kwargs = {'num_workers': args.workers, 'pin_memory': True}\n",
    "        self.train_loader, self.val_loader, self.test_loader, self.nclass = make_data_loader(args, **kwargs)\n",
    "        \n",
    "        self.cuda = args.useCUDA and torch.cuda.is_available()\n",
    "        if self.cuda:\n",
    "            args.gpu_ids = [int(s) for s in args.gpu_ids.split(',')]\n",
    "        if self.cuda and len(args.gpu_ids) > 1:\n",
    "            args.sync_bn = True\n",
    "        else:\n",
    "            args.sync_bn = False\n",
    "        # Define network\n",
    "        # DeepLab version\n",
    "#         model = DeepLab(backbone=args.backbone, output_stride=args.out_stride, num_classes=self.nclass, sync_bn=args.sync_bn, \n",
    "#                         freeze_bn=args.freeze_bn)\n",
    "#       # set different learning rate for backbone(ResNet101), Atrous Spatial Pyramid Pooling and decoder part\n",
    "#         train_params = [{'params': model.get_1x_lr_params(), 'lr': args.lr}, \n",
    "#                         {'params': model.get_10x_lr_params(), 'lr': args.lr * 10}]\n",
    "#         # Define Optimizer\n",
    "#         optimizer = torch.optim.SGD(train_params, momentum=args.momentum,\n",
    "#                                     weight_decay=args.weight_decay, nesterov=args.nesterov)\n",
    "        # UNet version\n",
    "        model = UNet(num_classes=self.nclass, sync_bn=args.sync_bn, freeze_bn=args.freeze_bn)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay, nesterov=args.nesterov)\n",
    "        \n",
    "        weight = None\n",
    " \n",
    "        \n",
    "        self.criterion = SegmentationLosses(weight=weight, cuda=self.cuda).build_loss(mode=args.loss_type) #pytorch cross-entropy loss\n",
    "        self.model, self.optimizer = model, optimizer\n",
    "        self.evaluator = Evaluator(self.nclass)\n",
    "        self.scheduler = LR_Scheduler(args.lr_scheduler, args.lr, args.epochs, len(self.train_loader))\n",
    "        \n",
    "            # Using cuda\n",
    "        if self.cuda:\n",
    "            self.model = torch.nn.DataParallel(self.model, device_ids=args.gpu_ids) # only use single GPU in my local machine\n",
    "            patch_replication_callback(self.model) # replicate the model to each GPU\n",
    "            self.model = self.model.cuda()\n",
    "        self.best_pred = 0.0\n",
    "        \n",
    "    def training(self, epoch):\n",
    "        train_loss = 0.0\n",
    "        self.model.train()\n",
    "        tbar = tqdm(self.train_loader)\n",
    "        num_img_tr = len(self.train_loader)\n",
    "\n",
    "        for i, sample in enumerate(tbar):\n",
    "            image, target = sample['image'], sample['label']\n",
    "            if self.cuda:\n",
    "                image, target = image.cuda(), target.cuda() # send mini-batches to GPU\n",
    "            self.scheduler(self.optimizer, i, epoch, self.best_pred)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(image)\n",
    "            loss = self.criterion(output, target)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            tbar.set_description('Train loss: {0:.3f}'.format(train_loss / (i + 1))) # keep track of average train loss\n",
    "            self.writer.add_scalar('train/total_loss_iter', loss.item(), i + num_img_tr * epoch)\n",
    "            # Show 10 * 3 inference results each epoch\n",
    "            if i % (num_img_tr // 10) == 0:\n",
    "                global_step = i + num_img_tr * epoch\n",
    "                self.summary.visualize_image(self.writer, self.args.dataset, image, target, output, global_step)\n",
    "\n",
    "        self.writer.add_scalar('train/total_loss_epoch', train_loss, epoch)\n",
    "        print('[Epoch: {0:d}, numImages: {0:5d}]'.format(epoch, i * self.args.batch_size + image.data.shape[0]))\n",
    "        print('Loss: {0:.3f}'.format(train_loss))\n",
    "\n",
    "    def validation(self, epoch):\n",
    "        self.model.eval()\n",
    "        self.evaluator.reset()\n",
    "        tbar = tqdm(self.val_loader, desc='\\r')\n",
    "        test_loss = 0.0\n",
    "\n",
    "        for i, sample in enumerate(tbar):\n",
    "            image, target = sample['image'], sample['label']\n",
    "            if self.cuda:\n",
    "                image, target = image.cuda(), target.cuda()\n",
    "                with torch.no_grad(): # no backpropagation for model evaludation\n",
    "                    output = self.model(image)\n",
    "                loss = self.criterion(output, target)\n",
    "                val_loss += loss.item()\n",
    "                tbar.set_description('Validation loss: {0:.3f}'.format(val_loss / (i + 1)))\n",
    "                pred = output.data.cpu().numpy()\n",
    "                target = target.cpu().numpy()\n",
    "                pred = np.argmax(pred, axis=1)\n",
    "                # Add batch sample into evaluator\n",
    "                # this will generate confusion matrix row: ground_truth, col: predicted label\n",
    "                self.evaluator.add_batch(target, pred)\n",
    "\n",
    "        # Fast evaludation during training\n",
    "        Acc = self.evaluator.Pixel_Accuracy()\n",
    "        Acc_class = self.evaluator.Pixel_Accuracy_Class()\n",
    "        mIoU = self.evaluator.Mean_Intersection_over_Union()\n",
    "        FWIoU = self.evaluator.Frequency_Weighted_Intersection_over_Union()\n",
    "\n",
    "        # Write current evaluation metrics to tensorboard\n",
    "        self.writer.add_scalar('val/total_loss_epoch', test_loss, epoch)\n",
    "        self.writer.add_scalar('val/mIoU', mIoU, epoch)\n",
    "        self.writer.add_scalar('val/Acc', Acc, epoch)\n",
    "        self.writer.add_scalar('val/Acc_class', Acc_class, epoch)\n",
    "        self.writer.add_scalar('val/fwIoU', FWIoU, epoch)\n",
    "        print('Validation:')\n",
    "        print('[Epoch: {0:d}, numImages: {0:5d}]'.format(epoch, i * self.args.batch_size + image.data.shape[0]))\n",
    "        print(\"Acc:{}, Acc_class:{}, mIoU:{}, fwIoU: {}\".format(Acc, Acc_class, mIoU, FWIoU))\n",
    "        print('Loss: {0:.3f}'.format(test_loss))\n",
    "\n",
    "        new_pred = mIoU\n",
    "        if new_pred > self.best_pred:\n",
    "            is_best = True\n",
    "            self.best_pred = new_pred\n",
    "            self.saver.save_checkpoint({'epoch': epoch + 1, 'state_dict': self.model.module.state_dict(), \n",
    "                                        'optimizer': self.optimizer.state_dict(), 'best_pred': self.best_pred}, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.57s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.70s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bluep\\Desktop\\Machine_Learning_Career_Track\\Springboard-Capstone\\code\\modeling\\unet.py:85: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using poly LR Scheduler!\n",
      "Total Epoches: 10\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42) # set random seed for both CPU and GPU\n",
    "trainer = Trainer(args)\n",
    "print('Total Epoches:', trainer.args.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/975 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'module' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c279d5071116>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_val\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_interval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_interval\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-5c1679ab9ddb>\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mnum_img_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m             \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1105\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1108\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    717\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle 'module' object"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, trainer.args.epochs):\n",
    "        trainer.training(epoch)\n",
    "        if not trainer.args.no_val and epoch % args.eval_interval == (args.eval_interval - 1):\n",
    "            trainer.validation(epoch)\n",
    "trainer.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.bincount(np.array([0, 1, 1, 3, 2, 1, 7]))\n",
    "np.nanmean()\n",
    "print(count)\n",
    "# count.reshape(7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_image = np.array([[0, 1, 1], [2, 0, 1], [1, 2, 0]])\n",
    "pre_image = np.array([[0, 0, 1], [2, 1, 1], [2, 0, 1]])\n",
    "_generate_matrix(3, gt_image,pre_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
